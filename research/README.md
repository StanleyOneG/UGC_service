Код тестов исследования расположен в соответствующих директориях по названием технологий.

Для запуска:

1. перейти в соответствующую директорию и выпонить

    ```shell
    docker compose up --build -d
    ```
2. выполнить (названия locust контейнера см. в соответствующем docker-compose.yaml файлах)

    ```shell
    docker exec -it <locust_container_name> bash
    ```

3. выполнить (названия .py файлов см. в соответствующих директории)

    ```shell
    locust -f <load_test_insert_.py> или <load_test_query_.py>
    ```

4. графический интерфейс будет доступен по адресу http://localhost:8089


Графики с результатами тестов представлены HTML документами, которые можно открыть в редакторе кода

Все тесты выполнялись на облачном сервере со следующими характеристиками:

## Computer configuration

| RAM    | CPU |     OS     | Storage |
|:------:|:---:|------------|---------|
|  30GB  |  10 | Debian 11  |   SSD   |


<details>
<summary>Результаты исследования по выбору OLAP хранилища и хранилища событий</summary>

# Результаты исследования по выбору OLAP хранилища и хранилища событий

### Описание тестов

1. Для нагрузочного тестирования был выбран Python фреймворк **Locust**
2. Для исследования были выбраны следующие технологии:

    ----
    **OLAP**

    - ClickHouse
    - Vertica
    ----
    **Хранилище событий**
    - Kafka
    - EventStore
    ----

3. Для **OLAP** систем было выполнено два вида тестов:

    3.1 Подготовительное - загрузка тестовых данных (movie_id, progress_time) до 5 виртуальных пользователей пачками по 100 тыс. строк в течение 100 сек.
    3.2 Основное - запросы к системе на вычисление тестовых данных; до 500 одновременных пользователей в течение 120 сек.

4. Для **Хранилищь событий** был выполнен следующий тест:

    4.1 Отправка сообщения о событии (movie_id-progress_time) до 10 тыс. одновременных пользователей в течение 240 сек.



## Результаты исследования

**Вставка данных**

|     Name           | № Requests  | Avg response time (ms) |   Avg RPS       |
|:-------------------|:-----------:|:----------------------:|:---------------:|
|   **ClickHouse**   |    110    |          4100           |        1.1      |
|   Vertica          |    60     |          11000          |        0.6     |

### *Комментарии*

1. **ClickHouse** Показал результат лучше, как в скорости загрузки данных, так и в количестве обработынных обращений за одинаковое время.
2. За время теста ClickHouse смог обработать 110 запросов, что равняется 11 млн. 100 тыс. строк данных
3. Vertica за это же время смогла обработать только 60 запросов что равняется 6 млн. строк данных.

**Обработка данных**

|     Name           | № Requests  | Avg response time (ms) |   Avg RPS       |
|:-------------------|:-----------:|:----------------------:|:---------------:|
|   **ClickHouse**   |    4852    |          19000           |        39.5      |
|   Vertica          |    4059     |          11000          |        33.8     |

### *Комментарии*

- С точки зрения обработки данных ClickHouse также показал себя немного лучше, как в количестве обработанных запросов, так и в среднем кол-ве запросов в секунду.

----

**Хранилища событий**

**Обработка событий**

|     Name           | № Requests  | Avg response time (ms) |   Avg RPS       |
|:-------------------|:-----------:|:----------------------:|:---------------:|
|   **Kafka**        |    395247   |          1800           |      1631.1     |
|   EventStore       |    258968   |          60000         |      1066.3     |


### *Комментарии*

- В данных тестах лучше себя показала Kafka, т.к за одинаковое время она обработала намного больше запросов и с намного меньшим средним временем ответа.

## Итог исследования

- По итогам исследования было принято решение использовать Kafka и ClickHouse в нашем проекте.

</details>


<details>
<summary>Результаты исследования по выбору хранилища для пользовательского контента</summary>

# Результаты исследования по выбору хранилища для пользовательского контента

### Описание тестов

1. Для нагрузочного тестирования был также выбран Python фреймворк **Locust**
2. Для исследования были выбраны следующие технологии:

    ----
    **NoSQL**

    - MongoDB
    - Cassandra
    ----
    **РСУБД**
    - PostgreSQL
    ----

3. Для всех систем было выполнено два вида тестов:

    3.1 Загрузка тестовых данных до 1000 виртуальных пользователей в течение 100 сек.
    3.2 Получение данных - запросы к системе на вычисление тестовых данных; до 1000 одновременных пользователей в течение 100 сек.


## Результаты исследования

**Загрузка данных**

|     Name           | № Requests| Max response time (ms)  |   Avg RPS      |
|:-------------------|:---------:|:-----------------------:|:--------------:|
|   **Cassandra**    |    21909  |          220            |        217.7   |
|   MongoDB          |    20973  |          450            |        208.5   |
|   PostgreSQL       |    540    |          22             |        10.2    |


### *Комментарии*

1. **Cassandra** Показала результат немного лучше, как в скорости загрузки данных, так и в количестве обработынных обращений за одинаковое время.
2. PostgreSQL несмотря на быстрый отклик смог обработать намного меньше обращений.


**Запрос и обработка данных**

|     Name           | № Requests| Max response time (ms)  |   Avg RPS      |
|:-------------------|:---------:|:-----------------------:|:--------------:|
|   **MongoDB**      |    35144  |          130            |        347.9   |
|   PostgreSQL       |    11604  |          110            |        39.6    |
|   Cassandra        |    3197   |          2800           |        31.6    |

### *Комментарии*

1. **MongoDB** показала лучшие результаты в обработке и получении данных с большим отрывом как в скорости, так и в количестве обработанных запросов
2. Несмотря на хорошие показатели в загрузке данных, в обработке и получении данных Cassandra сильно уступила в тестах остальным системам


## Итог исследования

- По итогам исследования было принято решение использовать **MongoDB** в нашем проекте, т.к. в данной задаче решающим фактором была высокая эффективность обработки и получения данных пользователя.

</details>
